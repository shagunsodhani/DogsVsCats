{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from util import *\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'Resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5b699ecc0b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m data_transforms = {\n\u001b[1;32m      6\u001b[0m     TRAIN : transforms.Compose([\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'Resize'"
     ]
    }
   ],
   "source": [
    "image_mean = [0.485, 0.456, 0.406]\n",
    "image_std = [0.229, 0.224, 0.225]\n",
    "normalize = transforms.Normalize(mean=image_mean,\n",
    "                                     std=image_std)\n",
    "data_transforms = {\n",
    "    TRAIN : transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    VAL : transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    TEST : transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root=train_dir,\n",
    "                           transform = data_transforms[TRAIN])\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers = num_workers)\n",
    "\n",
    "val_dataset = ImageFolder(root=val_dir,\n",
    "                           transform = data_transforms[VAL])\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers = num_workers)\n",
    "\n",
    "test_dataset = ImageFolder(root=test_dir,\n",
    "                           transform = data_transforms[TEST])\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers = num_workers)\n",
    "\n",
    "class_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(image_mean)\n",
    "    std = np.array(image_std)\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    plt.imsave(\"final_data_augmentation.png\", inp)\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "batch_to_view = next(iter(train_loader))\n",
    "inputs, classes = batch_to_view[0][:4], batch_to_view[1][:4]\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(model_name=RESNET50, use_cuda=True):\n",
    "    model = None\n",
    "    if(model_name==RESNET50):\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = torch.nn.Linear(in_features=2048, out_features=2)\n",
    "    if(model_name==RESNET101):\n",
    "        model = models.resnet101(pretrained=True)\n",
    "        model.fc = torch.nn.Linear(in_features=2048, out_features=2)\n",
    "    if(use_cuda):\n",
    "        return model.cuda()\n",
    "    else:\n",
    "        return model.cuda()\n",
    "\n",
    "def get_loss_fn(use_cuda=True):\n",
    "    if(use_cuda):\n",
    "        return torch.nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "        return torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer(model, learning_rate):\n",
    "    return torch.optim.SGD(\n",
    "        model.fc.parameters(), learning_rate\n",
    "    )\n",
    "\n",
    "def get_lr_scheduler(optimizer, step_size = 100, gamma=0.1):\n",
    "    return torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "def persist_model(model_state, save_path):\n",
    "    torch.save(model_state, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelMetric():\n",
    "    '''class to track the avergae accuracy for the model with different datasets\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.correct_count = 0.0\n",
    "        self.total_count = 0.0\n",
    "        self.total_loss = 0.0\n",
    "    \n",
    "    def update(self, correct_count, count, loss):\n",
    "        self.correct_count+=correct_count\n",
    "        self.total_count+=count\n",
    "        if(use_cuda):\n",
    "            loss = loss.cpu().data.numpy()[0]\n",
    "        else:\n",
    "            loss = loss.data.numpy()[0]\n",
    "        self.total_loss+=loss*count\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return self.correct_count/self.total_count\n",
    "    \n",
    "    @property\n",
    "    def average_loss(self):\n",
    "        return self.total_loss/self.total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, labels):\n",
    "    \"\"\"Computes the number of correct matches in y_pred\"\"\"\n",
    "    _, predictions = y_pred.topk(k = 1, dim=1)\n",
    "    batch_size = labels.size(0)\n",
    "    correct_count = torch.sum(predictions.eq(labels.view(-1, 1).expand_as(predictions)))\n",
    "    if(use_cuda):\n",
    "        correct_count = correct_count.cpu().data.numpy()[0]\n",
    "    else:\n",
    "        correct_count = correct_count.data.numpy()[0]\n",
    "    total_count = labels.shape[0]\n",
    "    return (correct_count, total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val(model, val_loader, loss_fn, metric):\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for (images, labels) in val_loader:\n",
    "        images = torch.autograd.Variable(images, volatile=True)\n",
    "        labels = torch.autograd.Variable(labels, volatile=True)\n",
    "        if(use_cuda):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        predictions = model(images)\n",
    "        predictions_loss = loss_fn(predictions, labels)\n",
    "        num_correct_predictions, num_total_predictions = compute_accuracy(predictions, labels)\n",
    "        metric.update(num_correct_predictions, num_total_predictions, predictions_loss)\n",
    "        \n",
    "    print(\"Validation Accuracy = {}, Validation Loss = {}, Time Taken = {} seconds\".format(\n",
    "        metric.accuracy,\n",
    "        metric.average_loss,\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, metric = None):\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for (images, labels) in train_loader:\n",
    "        images = torch.autograd.Variable(images)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "        if(use_cuda):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        predictions = model(images)\n",
    "        predictions_loss = loss_fn(predictions, labels)\n",
    "        num_correct_predictions, num_total_predictions = compute_accuracy(predictions, labels)\n",
    "        metric.update(num_correct_predictions, num_total_predictions, predictions_loss)\n",
    "        optimizer.zero_grad()\n",
    "        predictions_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += predictions_loss.data[0]\n",
    "        \n",
    "    print(\"Training Accuracy = {}, Training Loss = {}, Time Taken = {} seconds\".format(\n",
    "        train_metric.accuracy,\n",
    "        train_metric.average_loss,\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model(model_name=model_name, \n",
    "                 use_cuda=use_cuda)\n",
    "loss_fn = get_loss_fn(use_cuda=use_cuda)\n",
    "optimizer = get_optimizer(model=model, \n",
    "                          learning_rate=learning_rate)\n",
    "lr_scheduler = get_lr_scheduler(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.9111219512195122, Training Loss = 0.3075514023187684, Time Taken = 195.81014132499695 seconds\n",
      "Validation Accuracy = 0.9808, Validation Loss = 0.10887750520706177, Time Taken = 19.21811270713806 seconds\n",
      "Training Accuracy = 0.9257560975609757, Training Loss = 0.24651705667739962, Time Taken = 175.1411817073822 seconds\n",
      "Validation Accuracy = 0.9818, Validation Loss = 0.09203216321468354, Time Taken = 18.182817935943604 seconds\n",
      "Training Accuracy = 0.9320487804878049, Training Loss = 0.21813855779267907, Time Taken = 184.09511303901672 seconds\n",
      "Validation Accuracy = 0.9832, Validation Loss = 0.08271238477230072, Time Taken = 16.136255502700806 seconds\n",
      "Training Accuracy = 0.9352682926829269, Training Loss = 0.20148264575149955, Time Taken = 181.74705481529236 seconds\n",
      "Validation Accuracy = 0.984, Validation Loss = 0.0762444590806961, Time Taken = 15.22849178314209 seconds\n",
      "Training Accuracy = 0.938, Training Loss = 0.18948536890483483, Time Taken = 177.28749561309814 seconds\n",
      "Validation Accuracy = 0.98464, Validation Loss = 0.0714937456893921, Time Taken = 15.916289567947388 seconds\n",
      "Training Accuracy = 0.9402439024390243, Training Loss = 0.18020999128425993, Time Taken = 183.84856939315796 seconds\n",
      "Validation Accuracy = 0.9849333333333333, Validation Loss = 0.06786110448042551, Time Taken = 15.082478523254395 seconds\n",
      "Training Accuracy = 0.9411567944250872, Training Loss = 0.17400768929512242, Time Taken = 176.74875140190125 seconds\n",
      "Validation Accuracy = 0.9855428571428572, Validation Loss = 0.06490477815014975, Time Taken = 15.474239826202393 seconds\n",
      "Training Accuracy = 0.9422987804878049, Training Loss = 0.1688298685721508, Time Taken = 188.96461868286133 seconds\n",
      "Validation Accuracy = 0.98595, Validation Loss = 0.062405710807442664, Time Taken = 21.891721725463867 seconds\n",
      "Training Accuracy = 0.943560975609756, Training Loss = 0.16376985679667816, Time Taken = 180.71494579315186 seconds\n",
      "Validation Accuracy = 0.9862666666666666, Validation Loss = 0.060392715668678286, Time Taken = 15.95999264717102 seconds\n",
      "Training Accuracy = 0.9444926829268293, Training Loss = 0.15977109951217, Time Taken = 180.52145147323608 seconds\n",
      "Validation Accuracy = 0.98656, Validation Loss = 0.058631186668872834, Time Taken = 15.504612445831299 seconds\n",
      "Training Accuracy = 0.9450110864745012, Training Loss = 0.1568574825453917, Time Taken = 183.54570126533508 seconds\n",
      "Validation Accuracy = 0.9867272727272727, Validation Loss = 0.057146039899912744, Time Taken = 16.76890802383423 seconds\n",
      "Training Accuracy = 0.9454552845528456, Training Loss = 0.15408729464639492, Time Taken = 176.03749442100525 seconds\n",
      "Validation Accuracy = 0.987, Validation Loss = 0.055891197405258816, Time Taken = 17.091192483901978 seconds\n",
      "Training Accuracy = 0.9459512195121951, Training Loss = 0.1516955845396246, Time Taken = 191.93532156944275 seconds\n",
      "Validation Accuracy = 0.9872, Validation Loss = 0.05481184494495392, Time Taken = 16.664861917495728 seconds\n",
      "Training Accuracy = 0.9464703832752613, Training Loss = 0.14949471828684158, Time Taken = 177.30742502212524 seconds\n",
      "Validation Accuracy = 0.9874, Validation Loss = 0.053729747612987246, Time Taken = 18.482422828674316 seconds\n",
      "Training Accuracy = 0.9469365853658537, Training Loss = 0.14751260346251774, Time Taken = 185.59118795394897 seconds\n",
      "Validation Accuracy = 0.98744, Validation Loss = 0.052884496274789174, Time Taken = 22.172025680541992 seconds\n",
      "Training Accuracy = 0.9474939024390244, Training Loss = 0.14550491693243384, Time Taken = 178.89587306976318 seconds\n",
      "Validation Accuracy = 0.987575, Validation Loss = 0.052058357701450585, Time Taken = 15.095000982284546 seconds\n",
      "Training Accuracy = 0.9478794835007174, Training Loss = 0.14389541128641223, Time Taken = 190.29599285125732 seconds\n",
      "Validation Accuracy = 0.9877176470588235, Validation Loss = 0.05123711017790963, Time Taken = 15.03210973739624 seconds\n",
      "Training Accuracy = 0.9483848238482385, Training Loss = 0.1423511935179311, Time Taken = 181.53190422058105 seconds\n",
      "Validation Accuracy = 0.9878222222222223, Validation Loss = 0.05053202098078198, Time Taken = 15.438948154449463 seconds\n",
      "Training Accuracy = 0.948772785622593, Training Loss = 0.14092768096709588, Time Taken = 180.86857986450195 seconds\n",
      "Validation Accuracy = 0.9879578947368421, Validation Loss = 0.049799009467426096, Time Taken = 16.526124000549316 seconds\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 1e6\n",
    "train_metric = ModelMetric()\n",
    "val_metric = ModelMetric()\n",
    "running_loss = 0\n",
    "early_stopping_counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train_metric = train(model = model,\n",
    "         train_loader = train_loader,\n",
    "         loss_fn = loss_fn, \n",
    "         optimizer = optimizer,\n",
    "         metric = train_metric)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    val_metric = val(model = model,\n",
    "                          val_loader = val_loader,\n",
    "                          loss_fn = loss_fn,\n",
    "                        metric = val_metric)\n",
    "    val_accuracy = val_metric.accuracy\n",
    "    val_loss = val_metric.average_loss\n",
    "    if(val_loss < best_val_loss):\n",
    "        best_val_loss = val_loss\n",
    "        model_state = {\n",
    "            EPOCH: epoch+1,\n",
    "            STATE_DICT: model.state_dict(),\n",
    "            VAL_ACCURACY: val_accuracy,\n",
    "            VAL_LOSS: val_loss\n",
    "        }\n",
    "        save_path = \"/u/sodhanis/projects/DogsVsCats/model/checkpoint_epoch_\"\\\n",
    "        +str(epoch)+\"_val_accuracy_\"+str(int(val_accuracy*1e4))+\"_val_loss_\"+str(int(val_loss*1e4))+\".path.tar\"\n",
    "        persist_model(model_state=model_state,\n",
    "                     save_path = save_path)\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter+=1\n",
    "        if(early_stopping_counter == early_stopping_criteria):\n",
    "            break\n",
    "            print(\"Early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_fn, metric):\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for (images, labels) in test_loader:\n",
    "        images = torch.autograd.Variable(images, volatile=True)\n",
    "        labels = torch.autograd.Variable(labels, volatile=True)\n",
    "        if(use_cuda):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        predictions = model(images)\n",
    "        predictions_loss = loss_fn(predictions, labels)\n",
    "        num_correct_predictions, num_total_predictions = compute_accuracy(predictions, labels)\n",
    "        metric.update(num_correct_predictions, num_total_predictions, predictions_loss)\n",
    "        \n",
    "    print(\"Test Accuracy = {}, Test Loss = {}, Time Taken = {} seconds\".format(\n",
    "        metric.accuracy,\n",
    "        metric.average_loss,\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return metric\n",
    "test_metric = ModelMetric()\n",
    "test_metric = test(model, test_loader, loss_fn, test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=2):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    for (i, (images, labels)) in enumerate(val_loader):\n",
    "        images = torch.autograd.Variable(images)\n",
    "        labels = torch.autograd.Variable(labels)\n",
    "        if(use_cuda):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(images.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "            imshow(images.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=was_training)\n",
    "                return\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = model.parameters()\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Total number of parameters in {} model = {}\".format(model_name, params))\n",
    "\n",
    "model_parameters = model.fc.parameters()\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Total number of trainable parameters in the finetuned {} model = {}\".format(model_name, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
